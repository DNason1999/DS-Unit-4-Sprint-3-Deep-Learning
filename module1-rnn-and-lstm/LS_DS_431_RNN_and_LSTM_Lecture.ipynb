{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_IizNKWLomoA"
   },
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "## *Data Science Unit 4 Sprint 3 Lesson 1*\n",
    "\n",
    "# Recurrent Neural Networks and Long Short Term Memory (LSTM)\n",
    "## _aka_ PREDICTING THE FUTURE!\n",
    "\n",
    "<img src=\"https://media.giphy.com/media/l2JJu8U8SoHhQEnoQ/giphy.gif\" width=480 height=356>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "> \"Yesterday's just a memory - tomorrow is never what it's supposed to be.\" -- Bob Dylan\n",
    "\n",
    "Wish you could save [Time In A Bottle](https://www.youtube.com/watch?v=AnWWj6xOleY)? With statistics you can do the next best thing - understand how data varies over time (or any sequential order), and use the order/time dimension predictively.\n",
    "\n",
    "A sequence is just any enumerated collection - order counts, and repetition is allowed. Python lists are a good elemental example - `[1, 2, 2, -1]` is a valid list, and is different from `[1, 2, -1, 2]`. The data structures we tend to use (e.g. NumPy arrays) are often built on this fundamental structure.\n",
    "\n",
    "A time series is data where you have not just the order but some actual continuous marker for where they lie \"in time\" - this could be a date, a timestamp, [Unix time](https://en.wikipedia.org/wiki/Unix_time), or something else. All time series are also sequences, and for some techniques you may just consider their order and not \"how far apart\" the entries are (if you have particularly consistent data collected at regular intervals it may not matter)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "44QZgrPUe3-Y"
   },
   "source": [
    "## Recurrent Neural Networks\n",
    "\n",
    "There's plenty more to \"traditional\" time series, but the latest and greatest technique for sequence data is recurrent neural networks. A recurrence relation in math is an equation that uses recursion to define a sequence - a famous example is the Fibonacci numbers:\n",
    "\n",
    "$F_n = F_{n-1} + F_{n-2}$\n",
    "\n",
    "For formal math you also need a base case $F_0=1, F_1=1$, and then the rest builds from there. But for neural networks what we're really talking about are loops:\n",
    "\n",
    "![Recurrent neural network](https://upload.wikimedia.org/wikipedia/commons/b/b5/Recurrent_neural_network_unfold.svg)\n",
    "\n",
    "The hidden layers have edges (output) going back to their own input - this loop means that for any time `t` the training is at least partly based on the output from time `t-1`. The entire network is being represented on the left, and you can unfold the network explicitly to see how it behaves at any given `t`.\n",
    "\n",
    "Different units can have this \"loop\", but a particularly successful one is the long short-term memory unit (LSTM):\n",
    "\n",
    "![Long short-term memory unit](https://upload.wikimedia.org/wikipedia/commons/thumb/6/63/Long_Short-Term_Memory.svg/1024px-Long_Short-Term_Memory.svg.png)\n",
    "\n",
    "There's a lot going on here - in a nutshell, the calculus still works out and backpropagation can still be implemented. The advantage (ane namesake) of LSTM is that it can generally put more weight on recent (short-term) events while not completely losing older (long-term) information.\n",
    "\n",
    "After enough iterations, a typical neural network will start calculating prior gradients that are so small they effectively become zero - this is the [vanishing gradient problem](https://en.wikipedia.org/wiki/Vanishing_gradient_problem), and is what RNN with LSTM addresses. Pay special attention to the $c_t$ parameters and how they pass through the unit to get an intuition for how this problem is solved.\n",
    "\n",
    "So why are these cool? One particularly compelling application is actually not time series but language modeling - language is inherently ordered data (letters/words go one after another, and the order *matters*). [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) is a famous and worth reading blog post on this topic.\n",
    "\n",
    "For our purposes, let's use TensorFlow and Keras to train RNNs with natural language. Resources:\n",
    "\n",
    "- https://github.com/keras-team/keras/blob/master/examples/imdb_lstm.py\n",
    "- https://keras.io/layers/recurrent/#lstm\n",
    "- http://adventuresinmachinelearning.com/keras-lstm-tutorial/\n",
    "\n",
    "Note that `tensorflow.contrib` [also has an implementation of RNN/LSTM](https://www.tensorflow.org/tutorials/sequences/recurrent)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eWrQllf8WEd-"
   },
   "source": [
    "### RNN/LSTM Sentiment Classification with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 975
    },
    "colab_type": "code",
    "id": "Ti23G0gRe3kr",
    "outputId": "bba9ae40-a286-49ed-d87b-b2946fb60ddf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 0s 0us/step\n",
      "25000 train sequences\n",
      "25000 test sequences\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "#Trains an LSTM model on the IMDB sentiment classification task.\n",
    "The dataset is actually too small for LSTM to be of any advantage\n",
    "compared to simpler, much faster methods such as TF-IDF + LogReg.\n",
    "**Notes**\n",
    "- RNNs are tricky. Choice of batch size is important,\n",
    "choice of loss and optimizer is critical, etc.\n",
    "Some configurations won't converge.\n",
    "- LSTM loss decrease patterns during training can be quite different\n",
    "from what you see with CNNs/MLPs/etc.\n",
    "'''\n",
    "from __future__ import print_function\n",
    "\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.datasets import imdb\n",
    "\n",
    "max_features = 20000\n",
    "# cut texts after this number of words (among top max_features most common words)\n",
    "maxlen = 80\n",
    "batch_size = 32\n",
    "\n",
    "print('Loading data...')\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 975
    },
    "colab_type": "code",
    "id": "Ti23G0gRe3kr",
    "outputId": "bba9ae40-a286-49ed-d87b-b2946fb60ddf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad sequences (samples x time)\n",
      "x_train shape: (25000, 80)\n",
      "x_test shape: (25000, 80)\n"
     ]
    }
   ],
   "source": [
    "print('Pad sequences (samples x time)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   15,   256,     4,     2,     7,  3766,     5,   723,    36,\n",
       "          71,    43,   530,   476,    26,   400,   317,    46,     7,\n",
       "           4, 12118,  1029,    13,   104,    88,     4,   381,    15,\n",
       "         297,    98,    32,  2071,    56,    26,   141,     6,   194,\n",
       "        7486,    18,     4,   226,    22,    21,   134,   476,    26,\n",
       "         480,     5,   144,    30,  5535,    18,    51,    36,    28,\n",
       "         224,    92,    25,   104,     4,   226,    65,    16,    38,\n",
       "        1334,    88,    12,    16,   283,     5,    16,  4472,   113,\n",
       "         103,    32,    15,    16,  5345,    19,   178,    32])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 975
    },
    "colab_type": "code",
    "id": "Ti23G0gRe3kr",
    "outputId": "bba9ae40-a286-49ed-d87b-b2946fb60ddf"
   },
   "outputs": [],
   "source": [
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=15,\n",
    "          validation_data=(x_test, y_test))\n",
    "score, acc = model.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7pETWPIe362y"
   },
   "source": [
    "### LSTM Text generation with Keras\n",
    "\n",
    "What else can we do with LSTMs? Since we're analyzing the *sequence*, we can do more than classify - we can *generate* text. I'ved pulled some news stories using [newspaper](https://github.com/codelucas/newspaper/).\n",
    "\n",
    "This example is drawn from the Keras [documentation](https://keras.io/examples/lstm_text_generation/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files = os.listdir('./articles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in Data\n",
    "\n",
    "data = []\n",
    "\n",
    "for file in data_files:\n",
    "    if file[-3:] == 'txt':\n",
    "        with open(f'./articles/{file}', 'r', errors='ignore') as f:\n",
    "            data.append(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode Data as Chars\n",
    "text = \" \".join(data)\n",
    "chars = list(set(text))\n",
    "char_int = {c:i for i,c in enumerate(chars)}\n",
    "int_char = {i:c for i,c in enumerate(chars)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Sequence Data\n",
    "\n",
    "maxlen = 40\n",
    "step = 5\n",
    "\n",
    "encoded = [char_int[c] for c in text]\n",
    "\n",
    "sequences = [] # Each element is 40 characters long\n",
    "next_chars = [] # One element for each sequence\n",
    "\n",
    "for i in range(0, len(encoded) - maxlen, step):\n",
    "    sequences.append(encoded[i : i + maxlen])\n",
    "    next_chars.append(encoded[i + maxlen])\n",
    "print('sequences:', len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify x & y\n",
    "\n",
    "\n",
    "x = np.zeros((len(sequences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sequences), len(chars)), dtype=np.bool)\n",
    "\n",
    "for i, sequence in enumerate(sequences):\n",
    "    for t, char in enumerate(sequence):\n",
    "        x[i,t,char] = 1\n",
    "        \n",
    "    y[i, next_chars[i]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180776, 40, 121)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "903916"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180776, 121)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0127 15:13:01.708234 16452 deprecation.py:506] From c:\\users\\dylan nason\\anaconda3\\envs\\u4-s2-nn\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "# build the model: a single LSTM\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_epoch_end(epoch, _):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(400):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0127 15:13:07.604696 16452 deprecation.py:323] From c:\\users\\dylan nason\\anaconda3\\envs\\u4-s2-nn\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "180736/180776 [============================>.] - ETA: 0s - loss: 2.8214\n",
      "----- Generating text after Epoch: 0\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"laim to merit a Bottomless Pinocchio, an\"\n",
      "laim to merit a Bottomless Pinocchio, an the sing the the the the the the the the the the the the tore ware the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the sore the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"laim to merit a Bottomless Pinocchio, an\"\n",
      "laim to merit a Bottomless Pinocchio, ant an romerad the tor the the an to sor ary an ans an an son want afs ans in the the fars an coor the wintate cile sire the the tor an the the the that ond on â€œpa on the sore coar the the saben on the the the sound Son thin The the the thes the bereant the tes ppate fare, wor tour and and on als or as yon the the the the te tho tar at an mire on lofer inger for at foris rodisg an tho the tine the\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"laim to merit a Bottomless Pinocchio, an\"\n",
      "laim to merit a Bottomless Pinocchio, anido fared tin, ealo fte forle coveder oalibariut Paepd.\n",
      "\n",
      "AdNAne hof Dat woug JSBsed tht sibBpWfav cil. an acektali sike ang anidekAveasd ShPoclmas sungsu Wolid mothe cauches wferliet or dave moontor ™fiand rimes. L-lopth uf on tocabras pnale the Zans waciklall tiare \"ecaiso pori-D anfot c.rsos ratphe dfive, anse facap cevmasiouterevlingingal dorg tha ad yesrâ€œWesthans AasKors ol io,sad â€™h0 ine \n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"laim to merit a Bottomless Pinocchio, an\"\n",
      "laim to merit a Bottomless Pinocchio, angiyg. poopelicd m2chouss os ofura lamperectyux cowimp chor divs aplytBeWraltâ€œvedptoe eyes Weang. €d 1nisy)Rsu7 Falilk woela0t whas.™t anco tuu,  harior, ogtita geagid csullec nuy ongpsivladREon Vldebegd d1, ˜os sf, beroâ€™ernse co pand ©ales Ghrh€™d carmor ciRt reorg the  auwe 1us ntofiNivos wuarecime theers nasCan verondmunlsy qondacpo epsigos owy œiadl.\n",
      "Afs enNb€ Inâ€¦T[astorle. Pountarnyar fo\n",
      "180776/180776 [==============================] - 675s 4ms/sample - loss: 2.8213\n",
      "Epoch 2/5\n",
      "180736/180776 [============================>.] - ETA: 0s - loss: 2.4059\n",
      "----- Generating text after Epoch: 1\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \" going to be the luckiest people because\"\n",
      " going to be the luckiest people because the the the the the sore the the the the the the the the the the prong the the the the the the the the the the the the the the corsed the the the the the sore the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the withe the the the the the the the the the the the the the th\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" going to be the luckiest people because\"\n",
      " going to be the luckiest people because that sheas she foll the to mas in the then ster tion restife in bles an the cors wis the to the the cand the thel the prethe the the serothlel hes the the the mall the the ting on the the to the the and wiven The the porithe sing and and by in ther solt car the sredres was wat and corsting ar ard cachers ant cat wat the sorenting thin the the the that the nest mating the the has war bout in sered\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \" going to be the luckiest people because\"\n",
      " going to be the luckiest people becauses nof lyowed the €m rot on.â€œFas efmoungtred at actinc 2f redall we on for lensed war lake â€” â€ an toim holty th. Thim instolast in Nertiny arttrent our.\n",
      "â€™t wricd a sursintâ€¦ the mas ten chisley th a shet rous les. Euy hopich of â€œ[ked neftes aa-tat yroccurp bent aked nour (s hon har wrote. the cay lo tofont taruriched b-ontâ€™s Trs bitheât mist winge, in The ald wove miond ronemingy the la\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \" going to be the luckiest people because\"\n",
      " going to be the luckiest people because-efre breetd rewiccI Fhhast, clake truvin wethe c0eajr ow Ze inot thes lotiacle fserum tor Fens ins sdabbut ory HUthu he invâ€™2t thinint tore hur lckcwicet bumelidsro cting ilpwrentts Hanlyou the britipes ofere, relly Nos as jeyos ank 8os Deyor -motifher, ravoplros thisg cikengeteer on the Llins, wt ceud onmâ€\n",
      "â€ In.\n",
      "en J-”lirg to lHy Xiel. Fronp aly th lnla srced thiteac pelpmevors actis, mopl i\n",
      "180776/180776 [==============================] - 590s 3ms/sample - loss: 2.4059\n",
      "Epoch 3/5\n",
      "180736/180776 [============================>.] - ETA: 0s - loss: 2.2829\n",
      "----- Generating text after Epoch: 2\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"retreat forced our Kurdish allies, outma\"\n",
      "retreat forced our Kurdish allies, outmang the hat the has and the merich the heres and and and and and and and and and and and and and and and and the and and the has the and the preand and and and and and and and and and and and and the hes and the proment on the and and and on the the hes and and of the pration the pralition the the mast and the presing the the preast and and and the the hat and and and and and and and and and the pr\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"retreat forced our Kurdish allies, outma\"\n",
      "retreat forced our Kurdish allies, outmang on courpers allers and ases se the hat a pare to dishis the the coning and shat the cerpans ardumpligay the penound a bater seatall you to seress in the encang and mfor ta seater the arden and and ary and allly and andeas the and solle praas and sut dere the seane to pand deat and as the meres pormente the Candate for wiss ore the cainging the thite that here shate the preing he the ente son to\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"retreat forced our Kurdish allies, outma\"\n",
      "retreat forced our Kurdish allies, outmar shoums cramn, Unded hal T€ull 10]Pings. Hhink stedey tin Awand a nol corurt wimpyde, Nasbifvr iofy0ntey Tredio even; andain toe the Led Mam Houpe criges the racealg, thy uclices. Wistored lous.\n",
      "\n",
      "AD Af-Mentone and lomc.\n",
      "\n",
      "Mseres. Huge-laminting ro. mold Corth comEmasr, oulebses Trusgs ale in byines and cemitm A¦ Asprite bag Sthiovisturing urd in a Ruation liev the a bu deendromeny Mikly intavar in\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"retreat forced our Kurdish allies, outma\"\n",
      "retreat forced our Kurdish allies, outmalass ngalne tofe.\n",
      "\n",
      "Vwedâ€™shes shay Resercbeiv­of, ws thas hepleanev, anv bay owigesay, rethe JNandâ€â€™e untRed.S.\n",
      "\n",
      ". Somssienqupcngae shap fflas the ceblaniwe 'n lerts-ous. The dealler at founterointgorke â€¦ Bint. 1ivey, Wepprachious ouk, forsmy,â€Râ€™s larocy MizpCapd K7ointy-onga engnl©aynert st13 May) HaE Sp. Leand sÃony a, and):\n",
      "-AAEl sepad\n",
      "\n",
      "\n",
      "RAm-Abloten berdiased fthy thord the panst casay\n",
      "180776/180776 [==============================] - 570s 3ms/sample - loss: 2.2830\n",
      "Epoch 4/5\n",
      "180736/180776 [============================>.] - ETA: 0s - loss: 2.1991\n",
      "----- Generating text after Epoch: 3\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"rrier and people in those areas are star\"\n",
      "rrier and people in those areas are stare the conter and the the cand the wish the her and wish with the the the conger and and the the and and the the the the was sont of the contion the the hes and the the conting the prost the mand the the the proment of the the contion the the hes and whe the the seation and wish with the praching to the the has and with the reation the the has the reation and the has and of the the the wish the pro\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"rrier and people in those areas are star\"\n",
      "rrier and people in those areas are stard the parat enter she the and Singhome the tore the cand the revered the chate ars of the pralis compent of the wisther the Serime son periched a to chale of the grom for the conger the seatere the proves, apoury the to beed the proint compence to to the that the the reand the meate to wion the peest. He the resing whour, the wisthon to couply toed shay was the reas you deen. The Trump oflersed th\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"rrier and people in those areas are star\"\n",
      "rrier and people in those areas are star, in thed bas.\n",
      "\n",
      "Thimict prised fow neghel to to thatisutst, tho heres, thinj jonter bus downtion shized padtides, un Kerregrion Mngeorie thit coums, in Trump Wercea, Isrekyoneriged. Thou whhe wergonytre ty the vibye the teer cobace.â€ Ine tha disery, what dered allly, indiyil, deden.\n",
      "\n",
      "Swathers of thithed minN. Pece: ke, Pthive 7-.â€™e the exwl talt)od won Flyerused ot costh.\n",
      "\n",
      "Of a ilon, teappes an\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"rrier and people in those areas are star\"\n",
      "rrier and people in those areas are star.\n",
      "OLi)f toegk.\n",
      "\n",
      "Ilt one came. Thutikita: the fists toration ofdd bet averngoghe the Unop lace Trugd nawhan exark.\n",
      "\n",
      ". ton Popder Propich ot Kurpe in thel dawid $ray.)\n",
      "\n",
      "Abe Dateha Searsienfory withws,â€™ck rizarel wefthen leese haghat yat ploned quedlize oud inil #aple theliosine ow siage stion whean stow, fracrers.T\n",
      "\n",
      "Whoul, inthe 10.0 Hivicgâ€™s on the ratighing yoa crip.â€\n",
      "\n",
      "â) pxiist-moles EFlenog\n",
      "180776/180776 [==============================] - 564s 3ms/sample - loss: 2.1991\n",
      "Epoch 5/5\n",
      "180736/180776 [============================>.] - ETA: 0s - loss: 2.1368\n",
      "----- Generating text after Epoch: 4\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"r facts wrong,â€ he told Amons, shaking \"\n",
      "r facts wrong,â€ he told Amons, shaking the the promed a the resing a deand a deater a conger and with the reas and and a parte the reater and a delare to the reater and with the preated the has and a the promed the compers of the resere the read the was in the mesing the was seate the really the the prover a de in the wist on the reade to exper and with stide the wish a porter the wist a promed the perest on the wis of the wish on the \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"r facts wrong,â€ he told Amons, shaking \"\n",
      "r facts wrong,â€ he told Amons, shaking in the proper and a hele and the mated a wan you â€” were a dore were the conithe seapl her the hes of the diver a dear and with chis back be a dereded be the cerull chand a avent coull to the proust in the beting wat hat the the told a desions as the resiot of the his of the wist preasing the westian of the candented the wist the reveres on of the was rive was to a bich the Weres in pelices in in\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"r facts wrong,â€ he told Amons, shaking \"\n",
      "r facts wrong,â€ he told Amons, shaking meake nor in eCiles in to mestrowâ€ leel voftaim (lyt porth mace hes hecermoriten ourd, aladted of in is liol in his wa the reckencr suriles peobice that werer intontiding, wethe azentss inSacerre ouf shay loon wis scokaling ie payerite a dewtut to dendesalo ant metust on on with in gunkent and wast,-beotertiensed wurked he righe, lotinenits al youn acrens, or Thend ay ute tidest alliond yan, hay \n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"r facts wrong,â€ he told Amons, shaking \"\n",
      "r facts wrong,â€ he told Amons, shaking colpur muCs in 298 I Maice Uâ€¢Troowsay Mentunafdverum yoom p soude pornons in in tyemese beop ave the Myet parlebined cad in the lartur Neve cSucjiy Sinded,â€™s  usairriug to g.mâ€ rpraup ox ovel-sele, tild T0 CSarwator PaBtrazp, warvsnon1â€™s Wivee is, eber puecuedsilc Isrecedingiohr wilicit ansy panded the U intar,own lulo ervarhil ta den ie of tha ghot by the dambsed, -Ftust, theeas-anc6cuts: \n",
      "180776/180776 [==============================] - 552s 3ms/sample - loss: 2.1368\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x18f0e465388>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y,\n",
    "          batch_size=128,\n",
    "          epochs=5,\n",
    "          callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_441_RNN_and_LSTM.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
